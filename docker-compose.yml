# Definition of the custom network for container communication
networks:
  trains_network:
    driver: bridge  # Use the bridge network driver for isolated container communication

services:
  # Zookeeper service for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:latest  # Latest Zookeeper image from Confluent
    container_name: zookeeper  # Container name for easier identification
    hostname: zookeeper  # Hostname for internal communication within the network
    environment:
      ZOOKEEPER_SERVER_ID: 1  # Unique server ID for Zookeeper instance
      ZOOKEEPER_CLIENT_PORT: 2181  # Port for client connections
      ZOOKEEPER_TICK_TIME: 2000  # Basic time unit in milliseconds used for Zookeeper operations
    ports:
      - "2181:2181"  # Expose port 2181 for external client connections
    networks:
      - trains_network  # Connects the container to the custom network

  # Kafka service for message handling
  kafka:
    image: confluentinc/cp-kafka:latest  # Latest Kafka image from Confluent
    container_name: kafka  # Container name for easier identification
    hostname: kafka  # Hostname for internal communication within the network
    depends_on:
      - zookeeper  # Ensure Kafka starts after Zookeeper is running
    environment:
      KAFKA_BROKER_ID: 1  # Unique broker ID for Kafka instance
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  # Connect to Zookeeper using its hostname and port
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:19092  # Kafka listeners for internal and external communication
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:19092  # Binding Kafka to listen on specified ports
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE  # Specify the listener name for inter-broker communication
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT  # Define security protocols for listeners
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  # Replication factor for internal Kafka topic
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'  # Enable automatic creation of topics
    ports:
      - "9092:9092"  # Expose internal Kafka port for communication
      - "19092:19092"  # Expose external Kafka port for communication
    networks:
      - trains_network  # Connects the container to the custom network
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9092" ]  # Check if Kafka is running on port 9092
      interval: 10s  # Interval between health check attempts
      timeout: 5s  # Timeout for each health check
      retries: 5  # Number of retries before reporting the container as unhealthy

  # Data sensor simulator as Kafka producer
  data_sensor_simulator_kafka_producer:
    build:
      context: ./kafka_producer  # Path to the producer's Dockerfile
      dockerfile: Dockerfile  # Specify Dockerfile for building the image
    container_name: kafka_producer  # Container name for easier identification
    hostname: producer  # Hostname for internal communication
    environment:
      KAFKA_BROKER: 'kafka:9092'  # Kafka broker address for the producer to connect to
      TOPIC_NAME: "train-sensor-data"  # Name of the Kafka topic to publish data to
    depends_on:
      - kafka  # Ensure the producer starts after Kafka is running
    networks:
      - trains_network  # Connects the container to the custom network
    entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python data_simulator.py"]  # Wait until Kafka is available, then start the Python script

  # Flask application as Kafka consumer
  flask_app_kafka_consumer:
    build:
      context: ./kafka_flask_consumer  # Path to the consumer's Dockerfile
      dockerfile: Dockerfile  # Specify Dockerfile for building the image
    container_name: kafka_flask_consumer  # Container name for easier identification
    hostname: consumer  # Hostname for internal communication
    environment:
      KAFKA_BROKER: 'kafka:9092'  # Kafka broker address for the consumer to connect to
      TOPIC_NAME: 'train-sensor-data'  # Name of the Kafka topic to consume data from
    ports:
      - "5000:5000"  # Expose port 5000 for external access to the Flask app
    depends_on:
      - kafka  # Ensure the consumer starts after Kafka is running
    networks:
      - trains_network  # Connects the container to the custom network
    entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "flask run"]  # Wait until Kafka is available, then start the Flask server

  # Synthetic data generator as Kafka producer
  synthetic_data_sensor_generator_kafka_producer:
    build:
      context: ./real_kafka_producer  # Path to the synthetic producer's Dockerfile
      dockerfile: Dockerfile  # Specify Dockerfile for building the image
    container_name: real_kafka_producer  # Container name for easier identification
    hostname: real_producer  # Hostname for internal communication
    environment:
      KAFKA_BROKER: 'kafka:9092'  # Kafka broker address for the producer to connect to
      TOPIC_NAME: "train-sensor-data"  # Name of the Kafka topic to publish synthetic data to
    depends_on:
      - kafka  # Ensure the producer starts after Kafka is running
    networks:
      - trains_network  # Connects the container to the custom network
    entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python synthetic_data_generator.py"]  # Wait until Kafka is available, then start the Python script
