# Definition of the custom network
networks:
  trains_network:
    driver: bridge

services:
  # Zookeeper service for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    hostname: zookeeper
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181" # Exposes port 2181 for client connections
    networks:
      - trains_network

  # Kafka service for message handling
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    hostname: kafka
    depends_on:
      - zookeeper # Kafka depends on Zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:19092
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:19092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    ports:
      - "9092:9092" # Internal port for Kafka
      - "19092:19092" # External port for Kafka
    networks:
      - trains_network
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9092" ] # Health check to ensure Kafka is running
      interval: 10s
      timeout: 5s
      retries: 5

  # Data sensor simulator as Kafka producer
  data_sensor_simulator_kafka_producer:
    build:
      context: ./kafka_producer # Path to the producer's Dockerfile
      dockerfile: Dockerfile
    container_name: kafka_producer
    hostname: producer
    environment:
      KAFKA_BROKER: 'kafka:9092' # Kafka broker to connect to
      TOPIC_NAME: "train-sensor-data" # Kafka topic name
    depends_on:
      - kafka # Producer depends on Kafka
    networks:
      - trains_network
    entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python data_simulator.py"] # Starts the Python script after Kafka is available

  # Flask application as Kafka consumer
  flask_app_kafka_consumer:
    build:
      context: ./kafka_consumer # Path to the consumer's Dockerfile
      dockerfile: Dockerfile
    container_name: kafka_consumer
    hostname: consumer
    environment:
      KAFKA_BROKER: 'kafka:9092' # Kafka broker to connect to
      TOPIC_NAME: 'train-sensor-data' # Kafka topic name
    ports:
      - "5000:5000" # Port for the Flask app
    depends_on:
      - kafka # Consumer depends on Kafka
    networks:
      - trains_network
    entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "flask run"] # Starts the Flask server after Kafka is available

  # Data sensor simulator as Kafka producer
  synthetic_data_sensor_generator_kafka_producer:
    build:
      context: ./real_kafka_producer # Path to the producer's Dockerfile
      dockerfile: Dockerfile
    container_name: real_kafka_producer
    hostname: real_producer
    environment:
      KAFKA_BROKER: 'kafka:9092' # Kafka broker to connect to
      TOPIC_NAME: "train-sensor-data" # Kafka topic name
    depends_on:
      - kafka # Producer depends on Kafka
    networks:
      - trains_network
    entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python synthetic_data_generator.py"] # Starts the Python script after Kafka is available
