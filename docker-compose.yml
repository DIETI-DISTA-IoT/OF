# Definition of the custom network for container communication
networks:
  trains_network:
    driver: bridge  # Use the bridge network driver for isolated container communication

services:
  # Zookeeper service for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:latest  # Latest Zookeeper image from Confluent
    container_name: zookeeper  # Container name for easier identification
    hostname: zookeeper  # Hostname for internal communication within the network
    environment:
      ZOOKEEPER_SERVER_ID: 1  # Unique server ID for the Zookeeper instance
      ZOOKEEPER_CLIENT_PORT: 2181  # Port for client connections to Zookeeper
      ZOOKEEPER_TICK_TIME: 2000  # Time unit (in milliseconds) used by Zookeeper for internal operations
    ports:
      - "2181:2181"  # Expose port 2181 to allow external clients to connect
    networks:
      - trains_network  # Connect Zookeeper to the custom Docker network

  # Kafka service for message handling
  kafka:
    image: confluentinc/cp-kafka:latest  # Latest Kafka image from Confluent
    container_name: kafka  # Container name for easier identification
    hostname: kafka  # Hostname for internal communication within the network
    depends_on:
      - zookeeper  # Ensure Kafka starts only after Zookeeper is running
    environment:
      KAFKA_BROKER_ID: 1  # Unique identifier for this Kafka broker
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  # Address to connect to Zookeeper
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:19092  # Listeners for internal and external communication
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:19092  # Ports to bind Kafka to for listening
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE  # Listener for internal Kafka broker communication
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT  # Security protocol mappings for each listener
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  # Replication factor for internal Kafka topics
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'  # Automatically create topics when required
    ports:
      - "9092:9092"  # Expose Kafka's internal communication port
      - "19092:19092"  # Expose Kafka's external communication port
    networks:
      - trains_network  # Connect Kafka to the custom Docker network
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9092" ]  # Command to check if Kafka is running
      interval: 10s  # Time interval between health checks
      timeout: 5s  # Maximum time to wait for the health check
      retries: 5  # Retry count before reporting the container as unhealthy

  
  # Flask application as Kafka consumer
  # dashboard:
  #   build:
  #     context: ./dashboard  # Path to the consumer's Dockerfile
  #     dockerfile: Dockerfile  # Specify the Dockerfile for building the image
  #   container_name: dashboard  # Container name for easier identification
  #   hostname: dashboard  # Hostname for internal communication
  #   environment:
  #     KAFKA_BROKER: 'kafka:9092'  # Kafka broker address for the consumer to connect to
  #     TOPIC_NAME: 'train-sensor-data'  # Kafka topic to consume sensor data
  #     WANDB_API_KEY: ${WANDB_API_KEY}
  #   ports:
  #     - "5000:5000"  # Expose Flask's port for external access
  #   depends_on:
  #     - kafka  # Ensure the consumer starts only after Kafka is running
  #   networks:
  #     - trains_network  # Connect the consumer to the custom Docker network
  #   # entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "flask run"]  # Wait for Kafka to start before executing the Flask server
  #   command: ["tail", "-f", "/dev/null"]

  # Producer and Consumer pairs for the first vehicles
  producer:
    build:
      context: ./producer  # Path to the producer's Dockerfile
      dockerfile: Dockerfile  # Specify the Dockerfile for building the image
    container_name: producer  # Container name for easier identification
    hostname: producer  # Hostname for internal communication
    environment:
      WANDB_API_KEY: ${WANDB_API_KEY}
    depends_on:
      - kafka  # Ensure this producer starts only after Kafka is running
    networks:
      - trains_network  # Connect the producer to the custom Docker network
    # entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python produce.py"]  # Wait for Kafka before running the script
    command: ["tail", "-f", "/dev/null"]


  wandber:
    build:
      context: ./wandber  # Path to the producer's Dockerfile
      dockerfile: Dockerfile  # Specify the Dockerfile for building the image
    container_name: wandber  # Container name for easier identification
    hostname: wandber  # Hostname for internal communication
    environment:
      WANDB_API_KEY: ${WANDB_API_KEY}
    depends_on:
      - kafka  # Ensure this producer starts only after Kafka is running
    networks:
      - trains_network  # Connect the producer to the custom Docker network
    # entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python produce.py"]  # Wait for Kafka before running the script
    command: ["tail", "-f", "/dev/null"]


  consumer:
    build:
      context: ./consumer  # Path to the consumer's Dockerfile
      dockerfile: Dockerfile  # Specify the Dockerfile for building the image
    container_name: consumer  # Container name for easier identification
    hostname: consumer  # Hostname for internal communication
    environment:
      KAFKA_BROKER: 'kafka:9092'  # Kafka broker address
      VEHICLE_NAME: ${VEHICLE_NAME}
      WANDB_API_KEY: ${WANDB_API_KEY}
    depends_on:
      - kafka  # Ensure this consumer starts only after Kafka is running
    networks:
      - trains_network  # Connect the consumer to the custom Docker network
    # entrypoint: ["/wait-for-it.sh", "kafka:9092", "--", "sh", "-c", "python consume.py"]  # Wait for Kafka before running the script
    command: ["tail", "-f", "/dev/null"]

